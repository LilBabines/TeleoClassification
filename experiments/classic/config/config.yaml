hydra:
  run:
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}

data:
  dataset_path: "data/TeleoSplitGenera_300_medium"

task:
  task: "multitaxa" # multiaxa or signletaxa
  taxa_classes : ["order", "family"]

trainer:
  accelerator: "gpu"
  devices: 1
  per_device_train_batch_size : 16
  per_device_eval_batch_size : 16
  num_train_epochs : 20
  eval_delay : 0
  eval_strategy : "epoch"
  save_strategy : "no"
  load_best_model_at_end: True
  metric_for_best_model: "f1"
  greater_is_better: True
  push_to_hub : False

model:
  model_name: "zhihan1996/DNABERT-2-117M"
  tokenizer_name: "zhihan1996/DNABERT-2-117M"
  max_length: 512
  batch_size: 4
  learning_rate: 1e-5
  warmup_steps: 500
  weight_decay: 0.01
  gradient_accumulation_steps: 1

optimizer:
  learning_rate : 1e-5
  weight_decay : 0.01
  loss : "cross_entropy" # cross_entropy or BCEWithLogitsLoss
  metrics :
    macro_f1:
      callable: 'Fmetrics.classification.f1_score'
      kwargs: 
        average: 'macro'
    macro_accuracy:
      callable: 'Fmetrics.classification.macro_accuracy'
      kwargs:
        average: 'macro'
    micro_f1:
      callable: 'Fmetrics.classification.f1_score'
      kwargs: 
        average: 'micro'
    micro_accuracy:
      callable: 'Fmetrics.classification.micro_accuracy'
      kwargs:
        average: 'micro'



  
